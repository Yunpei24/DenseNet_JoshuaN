{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsDQCybacFyR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Naw3-f1Rtnko"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Training on device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MQwHm6nktNt"
      },
      "source": [
        "#I. Building Blocks of DenseNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DBgMjuPkwwK"
      },
      "source": [
        "We'll start by implementing the core components of the DenseNet architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4HHFGQHZed2"
      },
      "source": [
        "## 1. DenseNet Simple Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQDqWo7NZY4e"
      },
      "source": [
        "The simple layer in a DenseNet consists of a Batch Normalization layer, a ReLU activation function, and a 3x3 Convolutional layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufK29vohYtax"
      },
      "outputs": [],
      "source": [
        "class DenseNetSimpleLayer(nn.Module):\n",
        "  def __init__(self, in_channels, growth_rate):\n",
        "      \"\"\"\n",
        "      Initializes the DenseNet Simple Layer.\n",
        "\n",
        "      Args:\n",
        "          in_channels (int): Number of input channels.\n",
        "          growth_rate (int): Number of output channels (k in the paper).\n",
        "      \"\"\"\n",
        "      super(DenseNetSimpleLayer, self).__init__()\n",
        "      self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "      self.relu1 = nn.ReLU(inplace=True)\n",
        "      self.conv1 = nn.Conv2d(in_channels, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "      \"\"\"\n",
        "      Forward pass of the DenseNet Simple Layer.\n",
        "\n",
        "      Args:\n",
        "          x (torch.Tensor): Input tensor.\n",
        "\n",
        "      Returns:\n",
        "          torch.Tensor: Output tensor.\n",
        "      \"\"\"\n",
        "      out = self.conv1(self.relu1(self.bn1(x)))\n",
        "      out = torch.cat([x, out], 1)\n",
        "      return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKiqfG3YZiw_"
      },
      "source": [
        "##2. DenseNet Bottleneck Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPbZ_XHRZonA"
      },
      "source": [
        "The bottleneck layer is a more computationally efficient version of the simple layer. It introduces a 1x1 convolution to reduce the number of feature maps before the more expensive 3x3 convolution. The 1x1 convolution produces 4 * growth_rate feature maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV0GBHKpZnys"
      },
      "outputs": [],
      "source": [
        "class DenseNetBottleneckLayer(nn.Module):\n",
        "  def __init__(self, in_channels, growth_rate):\n",
        "      \"\"\"\n",
        "      Initializes the DenseNet Bottleneck Layer.\n",
        "\n",
        "      Args:\n",
        "          in_channels (int): Number of input channels.\n",
        "          growth_rate (int): Number of output channels for the 3x3 convolution.\n",
        "      \"\"\"\n",
        "      super(DenseNetBottleneckLayer, self).__init__()\n",
        "      inter_channels = 4 * growth_rate\n",
        "      self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "      self.relu1 = nn.ReLU(inplace=True)\n",
        "      self.conv1 = nn.Conv2d(in_channels, inter_channels, kernel_size=1, stride=1, bias=False)\n",
        "\n",
        "      self.bn2 = nn.BatchNorm2d(inter_channels)\n",
        "      self.relu2 = nn.ReLU(inplace=True)\n",
        "      self.conv2 = nn.Conv2d(inter_channels, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "      \"\"\"\n",
        "      Forward pass of the DenseNet Bottleneck Layer.\n",
        "\n",
        "      Args:\n",
        "          x (torch.Tensor): Input tensor.\n",
        "\n",
        "      Returns:\n",
        "          torch.Tensor: Output tensor.\n",
        "      \"\"\"\n",
        "      out = self.conv1(self.relu1(self.bn1(x)))\n",
        "      out = self.conv2(self.relu2(self.bn2(out)))\n",
        "      out = torch.cat([x, out], 1)\n",
        "      return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFYGqXe1aiHi"
      },
      "source": [
        "## 3. Transition Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq3b_s49alH0"
      },
      "source": [
        "The transition layer connects two dense blocks. It consists of a Batch Normalization layer, a 1x1 Convolutional layer to reduce the number of channels (compression), and an Average Pooling layer to reduce the spatial dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DTkPc_rZ_V9"
      },
      "outputs": [],
      "source": [
        "class TransitionLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \"\"\"\n",
        "        Initializes the Transition Layer.\n",
        "\n",
        "        Args:\n",
        "            in_channels (int): Number of input channels.\n",
        "            out_channels (int): Number of output channels.\n",
        "        \"\"\"\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
        "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Transition Layer.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor.\n",
        "        \"\"\"\n",
        "        out = self.conv1(self.relu1(self.bn1(x)))\n",
        "        out = self.avg_pool(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcMn67Guag8g"
      },
      "source": [
        "#II. Assembling the Full DenseNet Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i-iIQkukohX"
      },
      "source": [
        "Now we will combine these building blocks to create the complete DenseNet architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRil96_4k5xW"
      },
      "outputs": [],
      "source": [
        "class DenseNet(nn.Module):\n",
        "  def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10, init_weights=True, dataset_used=\"cifar10\"):\n",
        "    \"\"\"\n",
        "    Initializes the DenseNet model.\n",
        "\n",
        "    Args:\n",
        "        block (nn.Module): The type of dense layer to use (Simple or Bottleneck).\n",
        "        nblocks (list of int): The number of layers in each dense block.\n",
        "        growth_rate (int): The growth rate (k).\n",
        "        reduction (float): The compression factor for the transition layers.\n",
        "        num_classes (int): The number of output classes.\n",
        "        init_weights (bool): Whether to initialize the weights.\n",
        "        dataset_used (str): The dataset used for training.\n",
        "    \"\"\"\n",
        "    super(DenseNet, self).__init__()\n",
        "    self.growth_rate = growth_rate\n",
        "    num_planes = 2 * growth_rate\n",
        "\n",
        "    if dataset_used == \"cifar10\":\n",
        "      # Initial convolution for CIFAR-10\n",
        "      self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n",
        "    else:\n",
        "      # # Initial convolution for ImageNet\n",
        "      self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 2 * growth_rate, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(2 * growth_rate),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "    # First Dense Block\n",
        "    self.dense1 = self._make_dense_block(block, num_planes, nblocks[0])\n",
        "    num_planes += nblocks[0] * growth_rate\n",
        "    out_planes = int(num_planes * reduction)\n",
        "    self.trans1 = TransitionLayer(num_planes, out_planes)\n",
        "    num_planes = out_planes\n",
        "\n",
        "    # Second Dense Block\n",
        "    self.dense2 = self._make_dense_block(block, num_planes, nblocks[1])\n",
        "    num_planes += nblocks[1] * growth_rate\n",
        "    out_planes = int(num_planes * reduction)\n",
        "    self.trans2 = TransitionLayer(num_planes, out_planes)\n",
        "    num_planes = out_planes\n",
        "\n",
        "    # Third Dense Block\n",
        "    self.dense3 = self._make_dense_block(block, num_planes, nblocks[2])\n",
        "    num_planes += nblocks[2] * growth_rate\n",
        "    out_planes = int(num_planes * reduction)\n",
        "    self.trans3 = TransitionLayer(num_planes, out_planes)\n",
        "    num_planes = out_planes\n",
        "\n",
        "    # Fourth Dense Block\n",
        "    self.dense4 = self._make_dense_block(block, num_planes, nblocks[3])\n",
        "    num_planes += nblocks[3] * growth_rate\n",
        "\n",
        "    # Final layers\n",
        "    self.bn = nn.BatchNorm2d(num_planes)\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.linear = nn.Linear(num_planes, num_classes)\n",
        "\n",
        "    if init_weights:\n",
        "        self._initialize_weights()\n",
        "\n",
        "  def _make_dense_block(self, block, in_planes, nblock):\n",
        "      layers = []\n",
        "      for _ in range(nblock):\n",
        "          layers.append(block(in_planes, self.growth_rate))\n",
        "          in_planes += self.growth_rate\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "      for m in self.modules():\n",
        "          if isinstance(m, nn.Conv2d):\n",
        "              nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "              if m.bias is not None:\n",
        "                  nn.init.constant_(m.bias, 0)\n",
        "          elif isinstance(m, nn.BatchNorm2d):\n",
        "              nn.init.constant_(m.weight, 1)\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "          elif isinstance(m, nn.Linear):\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.conv1(x)\n",
        "      out = self.trans1(self.dense1(out))\n",
        "      out = self.trans2(self.dense2(out))\n",
        "      out = self.trans3(self.dense3(out))\n",
        "      out = self.dense4(out)\n",
        "      out = self.avg_pool(F.relu(self.bn(out)))\n",
        "      out = torch.flatten(out, 1)\n",
        "      out = self.linear(out)\n",
        "      return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NEz5SmMkLWO"
      },
      "source": [
        "#III. Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRacr3NYkUuN"
      },
      "outputs": [],
      "source": [
        "def Densenet_cifar():\n",
        "    return DenseNet(DenseNetBottleneckLayer, [6, 12, 24, 16], growth_rate=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecNTKmqOkaRi"
      },
      "outputs": [],
      "source": [
        "def DenseNet121():\n",
        "    return DenseNet(DenseNetBottleneckLayer, [6,12,24,16], growth_rate=32, dataset_used=\"imagenet\")\n",
        "\n",
        "def DenseNet169():\n",
        "    return DenseNet(DenseNetBottleneckLayer, [6,12,32,32], growth_rate=32, dataset_used=\"imagenet\")\n",
        "\n",
        "def DenseNet201():\n",
        "    return DenseNet(DenseNetBottleneckLayer, [6,12,48,32], growth_rate=32, dataset_used=\"imagenet\")\n",
        "\n",
        "def DenseNet161():\n",
        "    return DenseNet(DenseNetBottleneckLayer, [6,12,36,24], growth_rate=48, dataset_used=\"imagenet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y0quA22k4Qh"
      },
      "source": [
        "## 1. For CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXoH7CX9tK_X"
      },
      "outputs": [],
      "source": [
        "transform_train_cifar = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ks5xscyPtYFf"
      },
      "outputs": [],
      "source": [
        "# TRAINING FUNCTION\n",
        "\n",
        "def train(epoch, model, trainloader, optimizer, criterion, device):\n",
        "    print(f'\\nEpoch: {epoch}')\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch {epoch} | Batch {batch_idx}/{len(trainloader)} | Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f}% ({correct}/{total})')\n",
        "\n",
        "# EVALUATION FUNCTION\n",
        "\n",
        "def evaluate_cifar(model, testloader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    print(\"\\n--- Test Results ---\")\n",
        "    print(f\"Average Loss: {test_loss / len(testloader):.4f}\")\n",
        "    print(f\"Top-1 Accuracy: {acc:.2f}% ({correct}/{total})\")\n",
        "    print(\"--------------------\\n\")\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi6FsFI0tgXv"
      },
      "outputs": [],
      "source": [
        "# DataLoaders\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train_cifar)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test_cifar)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Use our from-scratch model\n",
        "model = densenet_cifar().to(device)\n",
        "print(\"Custom DenseNet model for CIFAR-10 created successfully.\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(200):\n",
        "    train(epoch, model, trainloader, optimizer, criterion, device)\n",
        "    evaluate_cifar(model, testloader, criterion, device)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WDhqeB5rr2o"
      },
      "source": [
        "## 2. For ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGBy4DvjrPOP"
      },
      "outputs": [],
      "source": [
        "# DATA LOADING AND TRANSFORMATION\n",
        "\n",
        "# ImageNet statistics\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# Data augmentation for the training set\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "# Transformation for the validation set\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KwZPBLXrWQ6"
      },
      "outputs": [],
      "source": [
        "# TRAINING FUNCTION\n",
        "def train_imagenet(epoch, model, trainloader, optimizer, criterion, device):\n",
        "    print(f'\\nEpoch: {epoch}')\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch {epoch} | Batch {batch_idx}/{len(trainloader)} | Loss: {train_loss/(batch_idx+1):.3f}')\n",
        "\n",
        "# EVALUATION FUNCTION (WITH TOP-1 AND TOP-5)\n",
        "def evaluate_imagenet(model, valloader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct_top1 = 0\n",
        "    correct_top5 = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(valloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate Top-1 and Top-5 accuracy\n",
        "            _, pred = outputs.topk(5, 1, largest=True, sorted=True)\n",
        "            pred = pred.t()\n",
        "            correct = pred.eq(targets.view(1, -1).expand_as(pred))\n",
        "\n",
        "            correct_top1 += correct[:1].reshape(-1).float().sum(0, keepdim=True).item()\n",
        "            correct_top5 += correct[:5].reshape(-1).float().sum(0, keepdim=True).item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "    # Calculate final accuracies\n",
        "    top1_acc = 100. * correct_top1 / total\n",
        "    top5_acc = 100. * correct_top5 / total\n",
        "\n",
        "    print(\"\\n--- Validation Results ---\")\n",
        "    print(f\"Average Loss: {val_loss / len(valloader):.4f}\")\n",
        "    print(f\"Top-1 Accuracy: {top1_acc:.2f}% ({int(correct_top1)}/{total})\")\n",
        "    print(f\"Top-5 Accuracy: {top5_acc:.2f}% ({int(correct_top5)}/{total})\")\n",
        "    print(\"--------------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwQZnlI1sEtB"
      },
      "outputs": [],
      "source": [
        "data_dir = './imagenette2'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "\n",
        "if not os.path.isdir(data_dir):\n",
        "  print(f\"Error: Dataset directory not found at '{data_dir}'\")\n",
        "  print(\"Please download a dataset like ImageNette and update the path.\")\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(root=val_dir, transform=transform_val)\n",
        "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=False, num_workers=4)\n",
        "\n",
        "# Use our from-scratch model, adjusting for the number of classes in the dataset\n",
        "num_classes = len(train_dataset.classes)\n",
        "model = DenseNet121(num_classes=num_classes).to(device)\n",
        "print(f\"Custom DenseNet-121 model for ImageNet created successfully with {num_classes} classes.\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "# Training Loop\n",
        "best_acc = 0.0\n",
        "for epoch in range(90):\n",
        "  train(epoch, model, trainloader, optimizer, criterion, device)\n",
        "  evaluate_imagenet(model, valloader, criterion, device)\n",
        "  scheduler.step()\n",
        "  # if acc > best_acc:\n",
        "  #     print(\"Saving new best model...\")\n",
        "  #     best_acc = acc\n",
        "  #     torch.save(model.state_dict(), 'densenet_imagenet_scratch_best.pth')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
