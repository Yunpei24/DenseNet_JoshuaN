{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:25:46.705096Z",
     "iopub.status.busy": "2025-08-25T14:25:46.704447Z",
     "iopub.status.idle": "2025-08-25T14:25:46.708569Z",
     "shell.execute_reply": "2025-08-25T14:25:46.707985Z",
     "shell.execute_reply.started": "2025-08-25T14:25:46.705070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:25:49.487935Z",
     "iopub.status.busy": "2025-08-25T14:25:49.487263Z",
     "iopub.status.idle": "2025-08-25T14:25:49.494771Z",
     "shell.execute_reply": "2025-08-25T14:25:49.494034Z",
     "shell.execute_reply.started": "2025-08-25T14:25:49.487908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_validation_set_from_kaggle(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Prepares the ImageNet validation set from the pre-extracted Kaggle directory structure.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): The root path to the Kaggle input data.\n",
    "        output_dir (str): The path to the writeable output directory (/kaggle/working/).\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"--- Preparing ONLY the validation set ---\")\n",
    "    \n",
    "    # Define paths\n",
    "    val_images_path = os.path.join(input_dir, 'ILSVRC/Data/CLS-LOC/val')\n",
    "    solution_file_path = os.path.join(input_dir, 'LOC_val_solution.csv')\n",
    "    \n",
    "    # The new sorted validation directory will be created in our workspace\n",
    "    sorted_val_dir = os.path.join(output_dir, 'val_sorted')\n",
    "    os.makedirs(sorted_val_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Reading solution file from: {solution_file_path}\")\n",
    "    # Read the CSV into a pandas DataFrame\n",
    "    df = pd.read_csv(solution_file_path)\n",
    "    \n",
    "    # The PredictionString contains the class ID (e.g., 'n01440764 1 2 3 4')\n",
    "    # We just need the first part.\n",
    "    df['class_id'] = df['PredictionString'].apply(lambda x: x.split(' ')[0])\n",
    "    \n",
    "    print(f\"Found {len(df)} images to sort.\")\n",
    "    print(f\"Copying and sorting images from {val_images_path} to {sorted_val_dir}...\")\n",
    "\n",
    "    # Loop through the dataframe and copy each file to its new class directory\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        image_id = row['ImageId']\n",
    "        class_id = row['class_id']\n",
    "        \n",
    "        # Create the destination class folder if it doesn't exist\n",
    "        dest_class_dir = os.path.join(sorted_val_dir, class_id)\n",
    "        os.makedirs(dest_class_dir, exist_ok=True)\n",
    "        \n",
    "        # Construct source and destination paths\n",
    "        src_path = os.path.join(val_images_path, image_id + '.JPEG')\n",
    "        dest_path = os.path.join(dest_class_dir, image_id + '.JPEG')\n",
    "        \n",
    "        # Copy the file\n",
    "        shutil.copyfile(src_path, dest_path)\n",
    "        \n",
    "    print(\"\\n--- Validation set preparation complete! ---\")\n",
    "    print(f\"Sorted validation data is ready in: {sorted_val_dir}\")\n",
    "    return sorted_val_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:25:49.694280Z",
     "iopub.status.busy": "2025-08-25T14:25:49.694104Z",
     "iopub.status.idle": "2025-08-25T14:25:58.694789Z",
     "shell.execute_reply": "2025-08-25T14:25:58.694248Z",
     "shell.execute_reply.started": "2025-08-25T14:25:49.694265Z"
    },
    "id": "EsDQCybacFyR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:25:58.696128Z",
     "iopub.status.busy": "2025-08-25T14:25:58.695786Z",
     "iopub.status.idle": "2025-08-25T14:25:58.763290Z",
     "shell.execute_reply": "2025-08-25T14:25:58.762560Z",
     "shell.execute_reply.started": "2025-08-25T14:25:58.696110Z"
    },
    "id": "Naw3-f1Rtnko",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS (Metal) is available!\n",
      "MPS (Metal) is built!\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(f\"Training on device: {device}\")\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS (Metal) is available!\")\n",
    "else:\n",
    "    print(\"MPS (Metal) is not available.\")\n",
    "\n",
    "if torch.backends.mps.is_built():\n",
    "    print(\"MPS (Metal) is built!\")\n",
    "else:\n",
    "    print(\"MPS (Metal) is not built.\")\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MQwHm6nktNt"
   },
   "source": [
    "# I. Building Blocks of DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DBgMjuPkwwK"
   },
   "source": [
    "We'll start by implementing the core components of the DenseNet architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4HHFGQHZed2"
   },
   "source": [
    "## 1. DenseNet Simple Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQDqWo7NZY4e"
   },
   "source": [
    "The simple layer in a DenseNet consists of a Batch Normalization layer, a ReLU activation function, and a 3x3 Convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:25:58.764394Z",
     "iopub.status.busy": "2025-08-25T14:25:58.764096Z",
     "iopub.status.idle": "2025-08-25T14:25:58.827063Z",
     "shell.execute_reply": "2025-08-25T14:25:58.826346Z",
     "shell.execute_reply.started": "2025-08-25T14:25:58.764373Z"
    },
    "id": "ufK29vohYtax",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DenseNetSimpleLayer(nn.Module):\n",
    "  def __init__(self, in_channels, growth_rate):\n",
    "      \"\"\"\n",
    "      Initializes the DenseNet Simple Layer.\n",
    "\n",
    "      Args:\n",
    "          in_channels (int): Number of input channels.\n",
    "          growth_rate (int): Number of output channels (k in the paper).\n",
    "      \"\"\"\n",
    "      super(DenseNetSimpleLayer, self).__init__()\n",
    "      self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "      self.relu1 = nn.ReLU(inplace=True)\n",
    "      self.conv1 = nn.Conv2d(in_channels, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "      \"\"\"\n",
    "      Forward pass of the DenseNet Simple Layer.\n",
    "\n",
    "      Args:\n",
    "          x (torch.Tensor): Input tensor.\n",
    "\n",
    "      Returns:\n",
    "          torch.Tensor: Output tensor.\n",
    "      \"\"\"\n",
    "      out = self.conv1(self.relu1(self.bn1(x)))\n",
    "      out = torch.cat([x, out], 1)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKiqfG3YZiw_"
   },
   "source": [
    "## 2. DenseNet Bottleneck Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPbZ_XHRZonA"
   },
   "source": [
    "The bottleneck layer is a more computationally efficient version of the simple layer. It introduces a 1x1 convolution to reduce the number of feature maps before the more expensive 3x3 convolution. The 1x1 convolution produces 4 * growth_rate feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:25:58.828520Z",
     "iopub.status.busy": "2025-08-25T14:25:58.828321Z",
     "iopub.status.idle": "2025-08-25T14:25:58.844358Z",
     "shell.execute_reply": "2025-08-25T14:25:58.843713Z",
     "shell.execute_reply.started": "2025-08-25T14:25:58.828503Z"
    },
    "id": "XV0GBHKpZnys",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DenseNetBottleneckLayer(nn.Module):\n",
    "  def __init__(self, in_channels, growth_rate, dropout_rate=0):\n",
    "      \"\"\"\n",
    "      Initializes the DenseNet Bottleneck Layer.\n",
    "\n",
    "      Args:\n",
    "          in_channels (int): Number of input channels.\n",
    "          growth_rate (int): Number of output channels for the 3x3 convolution.\n",
    "      \"\"\"\n",
    "      super(DenseNetBottleneckLayer, self).__init__()\n",
    "      inter_channels = 4 * growth_rate\n",
    "      self.dropout_rate = dropout_rate\n",
    "      self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "      self.relu1 = nn.ReLU(inplace=True)\n",
    "      self.conv1 = nn.Conv2d(in_channels, inter_channels, kernel_size=1, stride=1, bias=False)\n",
    "\n",
    "      self.bn2 = nn.BatchNorm2d(inter_channels)\n",
    "      self.relu2 = nn.ReLU(inplace=True)\n",
    "      self.conv2 = nn.Conv2d(inter_channels, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "      # Add dropout layer if specified\n",
    "      if self.dropout_rate > 0:\n",
    "          self.dropout = nn.Dropout2d(p=self.dropout_rate)\n",
    "          \n",
    "  def forward(self, x):\n",
    "      out = self.conv1(self.relu1(self.bn1(x)))\n",
    "      out = self.conv2(self.relu2(self.bn2(out)))\n",
    "      \n",
    "      # Apply dropout before concatenation\n",
    "      if self.dropout_rate > 0:\n",
    "        out = self.dropout(out)\n",
    "          \n",
    "      out = torch.cat([x, out], 1)\n",
    "      return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFYGqXe1aiHi"
   },
   "source": [
    "## 3. Transition Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nq3b_s49alH0"
   },
   "source": [
    "The transition layer connects two dense blocks. It consists of a Batch Normalization layer, a 1x1 Convolutional layer to reduce the number of channels (compression), and an Average Pooling layer to reduce the spatial dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:25:58.845222Z",
     "iopub.status.busy": "2025-08-25T14:25:58.844985Z",
     "iopub.status.idle": "2025-08-25T14:25:58.860369Z",
     "shell.execute_reply": "2025-08-25T14:25:58.859715Z",
     "shell.execute_reply.started": "2025-08-25T14:25:58.845205Z"
    },
    "id": "3DTkPc_rZ_V9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        Initializes the Transition Layer.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "        \"\"\"\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Transition Layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        out = self.conv1(self.relu1(self.bn1(x)))\n",
    "        out = self.avg_pool(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcMn67Guag8g"
   },
   "source": [
    "# II. Assembling the Full DenseNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i-iIQkukohX"
   },
   "source": [
    "Now we will combine these building blocks to create the complete DenseNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:25:58.861277Z",
     "iopub.status.busy": "2025-08-25T14:25:58.861088Z",
     "iopub.status.idle": "2025-08-25T14:25:58.873687Z",
     "shell.execute_reply": "2025-08-25T14:25:58.873060Z",
     "shell.execute_reply.started": "2025-08-25T14:25:58.861262Z"
    },
    "id": "wRil96_4k5xW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "  def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10, dropout_rate=0, init_weights=True, dataset_used=\"cifar\"):\n",
    "    \"\"\"\n",
    "    Initializes the DenseNet model.\n",
    "\n",
    "    Args:\n",
    "        block (nn.Module): The type of dense layer to use (Simple or Bottleneck).\n",
    "        nblocks (list of int): The number of layers in each dense block.\n",
    "        growth_rate (int): The growth rate (k).\n",
    "        reduction (float): The compression factor for the transition layers.\n",
    "        num_classes (int): The number of output classes.\n",
    "        init_weights (bool): Whether to initialize the weights.\n",
    "        dataset_used (str): The dataset used for training.\n",
    "    \"\"\"\n",
    "    super(DenseNet, self).__init__()\n",
    "    self.growth_rate = growth_rate\n",
    "    num_planes = 2 * growth_rate\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.dataset_used = dataset_used\n",
    "\n",
    "    if self.dataset_used == \"cifar\":\n",
    "      # Initial convolution for CIFAR-X\n",
    "      self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n",
    "    else:\n",
    "      # # Initial convolution for ImageNet\n",
    "      self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 2 * growth_rate, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(2 * growth_rate),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "    # First Dense Block\n",
    "    self.dense1 = self._make_dense_block(block, num_planes, nblocks[0])\n",
    "    num_planes += nblocks[0] * growth_rate\n",
    "    out_planes = int(num_planes * reduction)\n",
    "    self.trans1 = TransitionLayer(num_planes, out_planes)\n",
    "    num_planes = out_planes\n",
    "\n",
    "    # Second Dense Block\n",
    "    self.dense2 = self._make_dense_block(block, num_planes, nblocks[1])\n",
    "    num_planes += nblocks[1] * growth_rate\n",
    "    out_planes = int(num_planes * reduction)\n",
    "    self.trans2 = TransitionLayer(num_planes, out_planes)\n",
    "    num_planes = out_planes\n",
    "\n",
    "    # Third Dense Block\n",
    "    self.dense3 = self._make_dense_block(block, num_planes, nblocks[2])\n",
    "    num_planes += nblocks[2] * growth_rate\n",
    "      \n",
    "    if self.dataset_used != \"cifar\":\n",
    "        out_planes = int(num_planes * reduction)\n",
    "        self.trans3 = TransitionLayer(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "    \n",
    "        # Fourth Dense Block\n",
    "        self.dense4 = self._make_dense_block(block, num_planes, nblocks[3])\n",
    "        num_planes += nblocks[3] * growth_rate\n",
    "\n",
    "    # Final layers\n",
    "    self.bn = nn.BatchNorm2d(num_planes)\n",
    "    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    self.linear = nn.Linear(num_planes, num_classes)\n",
    "\n",
    "    if init_weights:\n",
    "        self._initialize_weights()\n",
    "\n",
    "  def _make_dense_block(self, block, in_planes, nblock):\n",
    "      layers = []\n",
    "      for _ in range(nblock):\n",
    "          layers.append(block(in_planes, self.growth_rate, self.dropout_rate))\n",
    "          in_planes += self.growth_rate\n",
    "      return nn.Sequential(*layers)\n",
    "\n",
    "  def _initialize_weights(self):\n",
    "      for m in self.modules():\n",
    "          if isinstance(m, nn.Conv2d):\n",
    "              nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "              if m.bias is not None:\n",
    "                  nn.init.constant_(m.bias, 0)\n",
    "          elif isinstance(m, nn.BatchNorm2d):\n",
    "              nn.init.constant_(m.weight, 1)\n",
    "              nn.init.constant_(m.bias, 0)\n",
    "          elif isinstance(m, nn.Linear):\n",
    "              nn.init.constant_(m.bias, 0)\n",
    "\n",
    "  def forward(self, x):\n",
    "      out = self.conv1(x)\n",
    "      out = self.trans1(self.dense1(out))\n",
    "      out = self.trans2(self.dense2(out))\n",
    "      if self.dataset_used != \"cifar\":\n",
    "          out = self.trans3(self.dense3(out))\n",
    "          out = self.dense4(out)\n",
    "      else:\n",
    "          out = self.dense3(out)\n",
    "      out = self.avg_pool(F.relu(self.bn(out)))\n",
    "      out = torch.flatten(out, 1)\n",
    "      out = self.linear(out)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NEz5SmMkLWO"
   },
   "source": [
    "# III. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:26:00.453115Z",
     "iopub.status.busy": "2025-08-25T14:26:00.452604Z",
     "iopub.status.idle": "2025-08-25T14:26:00.456922Z",
     "shell.execute_reply": "2025-08-25T14:26:00.456260Z",
     "shell.execute_reply.started": "2025-08-25T14:26:00.453092Z"
    },
    "id": "lRacr3NYkUuN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Densenet_cifar(k=12, dropout_rate=0, num_classes=10):\n",
    "    return DenseNet(DenseNetBottleneckLayer, [16, 16, 16], growth_rate=k, dropout_rate=dropout_rate, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:26:00.685429Z",
     "iopub.status.busy": "2025-08-25T14:26:00.684818Z",
     "iopub.status.idle": "2025-08-25T14:26:00.690046Z",
     "shell.execute_reply": "2025-08-25T14:26:00.689433Z",
     "shell.execute_reply.started": "2025-08-25T14:26:00.685404Z"
    },
    "id": "ecNTKmqOkaRi",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def DenseNet121():\n",
    "    return DenseNet(DenseNetBottleneckLayer, [6,12,24,16], growth_rate=32, dataset_used=\"imagenet\")\n",
    "\n",
    "def DenseNet169():\n",
    "    return DenseNet(DenseNetBottleneckLayer, [6,12,32,32], growth_rate=32, dataset_used=\"imagenet\")\n",
    "\n",
    "def DenseNet201():\n",
    "    return DenseNet(DenseNetBottleneckLayer, [6,12,48,32], growth_rate=32, dataset_used=\"imagenet\")\n",
    "\n",
    "def DenseNet161():\n",
    "    return DenseNet(DenseNetBottleneckLayer, [6,12,36,24], growth_rate=48, dataset_used=\"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Y0quA22k4Qh"
   },
   "source": [
    "## 1. For CIFAR-10 & 100 with simple data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:26:02.200471Z",
     "iopub.status.busy": "2025-08-25T14:26:02.200233Z",
     "iopub.status.idle": "2025-08-25T14:26:02.205328Z",
     "shell.execute_reply": "2025-08-25T14:26:02.204645Z",
     "shell.execute_reply.started": "2025-08-25T14:26:02.200455Z"
    },
    "id": "EXoH7CX9tK_X",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform_train_cifar = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test_cifar = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:26:07.445235Z",
     "iopub.status.busy": "2025-08-25T14:26:07.444946Z",
     "iopub.status.idle": "2025-08-25T14:26:07.452954Z",
     "shell.execute_reply": "2025-08-25T14:26:07.452247Z",
     "shell.execute_reply.started": "2025-08-25T14:26:07.445214Z"
    },
    "id": "Ks5xscyPtYFf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# TRAINING FUNCTION\n",
    "\n",
    "def train(epoch, model, trainloader, optimizer, criterion, device):\n",
    "        model.train()\n",
    "        print(f'\\nEpoch: {epoch} | LR: {optimizer.param_groups[0][\"lr\"]:.5f}')\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(enumerate(trainloader), total=len(trainloader))\n",
    "        for i, (inputs, targets) in progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                progress_bar.set_description(f'Loss: {running_loss/(i+1):.3f} | Acc: {100.*correct/total:.3f}%')\n",
    "\n",
    "\n",
    "# EVALUATION FUNCTION\n",
    "\n",
    "def evaluate_cifar(model, testloader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in testloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    accuracy = 100. * correct / total\n",
    "    error_rate = 100. - accuracy\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"--- Epoch {epoch} Test Results ---\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}% | Error Rate: {error_rate:.2f}%\")\n",
    "        print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:26:13.133850Z",
     "iopub.status.busy": "2025-08-25T14:26:13.133147Z"
    },
    "id": "Hi6FsFI0tgXv",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [02:22<00:00, 1.19MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "--- Use our from-scratch model with growth rate = 12 ---\n",
      "Custom DenseNet model for CIFAR-10 created successfully.\n",
      "\n",
      "Epoch: 0 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.425 | Acc: 47.578%: 100%|██████████| 391/391 [22:38<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 0 Test Results ---\n",
      "Accuracy: 55.65% | Error Rate: 44.35%\n",
      "--------------------------\n",
      "\n",
      "Epoch: 1 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [22:29<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [22:13<00:00,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [22:21<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [22:16<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [21:55<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [21:47<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [20:59<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [21:01<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [20:58<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.345 | Acc: 88.020%: 100%|██████████| 391/391 [20:38<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 10 Test Results ---\n",
      "Accuracy: 77.74% | Error Rate: 22.26%\n",
      "--------------------------\n",
      "\n",
      "Epoch: 11 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [20:18<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [20:17<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [20:20<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [17:51<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [18:39<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [20:40<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [21:07<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [26:59<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [25:40<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 20 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.236 | Acc: 91.752%: 100%|██████████| 391/391 [21:14<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 20 Test Results ---\n",
      "Accuracy: 86.84% | Error Rate: 13.16%\n",
      "--------------------------\n",
      "\n",
      "Epoch: 21 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [20:36<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 22 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [20:51<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 23 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [21:59<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 24 | LR: 0.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 375/391 [21:25<01:03,  3.97s/it]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 300\n",
    "# DataLoaders\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train_cifar)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test_cifar)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "for k in [12, 24]:\n",
    "\n",
    "    print(\"#\"*50)\n",
    "    print(f\"--- Use our from-scratch model with growth rate = {k} ---\")\n",
    "    model = Densenet_cifar(k=k).to(device)\n",
    "    print(\"Custom DenseNet model for CIFAR-10 created successfully.\")\n",
    "    \n",
    "    # --- Optimizer and Scheduler ---\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Optimizer settings from the paper: SGD, Nesterov momentum 0.9, weight decay 1e-4 \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    # LR schedule from the paper: divide by 10 at 50% and 75% of epochs \n",
    "    milestones = [int(EPOCHS * 0.5), int(EPOCHS * 0.75)]\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
    "    \n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch, model, trainloader, optimizer, criterion, device)\n",
    "        evaluate_cifar(model, testloader, criterion, device)\n",
    "        scheduler.step()\n",
    "    print(\"#\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WDhqeB5rr2o"
   },
   "source": [
    "## 2. For ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGBy4DvjrPOP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# DATA LOADING AND TRANSFORMATION\n",
    "\n",
    "# ImageNet statistics\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Data augmentation for the training set\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# Transformation for the validation set\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KwZPBLXrWQ6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# TRAINING FUNCTION\n",
    "def train_imagenet(epoch, model, trainloader, optimizer, criterion, device):\n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch} | Batch {batch_idx}/{len(trainloader)} | Loss: {train_loss/(batch_idx+1):.3f}')\n",
    "\n",
    "# EVALUATION FUNCTION (WITH TOP-1 AND TOP-5)\n",
    "def evaluate_imagenet(model, valloader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate Top-1 and Top-5 accuracy\n",
    "            _, pred = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(targets.view(1, -1).expand_as(pred))\n",
    "\n",
    "            correct_top1 += correct[:1].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "            correct_top5 += correct[:5].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    # Calculate final accuracies\n",
    "    top1_acc = 100. * correct_top1 / total\n",
    "    top5_acc = 100. * correct_top5 / total\n",
    "\n",
    "    print(\"\\n--- Validation Results ---\")\n",
    "    print(f\"Average Loss: {val_loss / len(valloader):.4f}\")\n",
    "    print(f\"Top-1 Accuracy: {top1_acc:.2f}% ({int(correct_top1)}/{total})\")\n",
    "    print(f\"Top-5 Accuracy: {top5_acc:.2f}% ({int(correct_top5)}/{total})\")\n",
    "    print(\"--------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = \"/kaggle/input/imagenet-object-localization-challenge\"\n",
    "OUTPUT_DIR = \"/kaggle/working/\"\n",
    "\n",
    "# This function will create and return the path to the sorted validation set\n",
    "sorted_val_path = prepare_validation_set_from_kaggle(input_dir=INPUT_DIR, output_dir=OUTPUT_DIR)\n",
    "\n",
    "# The training directory points DIRECTLY to the read-only input data. No copy needed!\n",
    "train_dir = os.path.join(INPUT_DIR, 'ILSVRC/Data/CLS-LOC/train')\n",
    "# The validation directory points to our newly created sorted folder\n",
    "val_dir = sorted_val_path\n",
    "\n",
    "print(f\"\\nUsing Training data from: {train_dir}\")\n",
    "print(f\"Using Validation data from: {val_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwQZnlI1sEtB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(root=val_dir, transform=transform_val)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "# Use our from-scratch model, adjusting for the number of classes in the dataset\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = DenseNet121(num_classes=num_classes).to(device)\n",
    "print(f\"Custom DenseNet-121 model for ImageNet created successfully with {num_classes} classes.\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# Training Loop\n",
    "best_acc = 0.0\n",
    "for epoch in range(90):\n",
    "  train(epoch, model, trainloader, optimizer, criterion, device)\n",
    "  evaluate_imagenet(model, valloader, criterion, device)\n",
    "  scheduler.step()\n",
    "  # if acc > best_acc:\n",
    "  #     print(\"Saving new best model...\")\n",
    "  #     best_acc = acc\n",
    "  #     torch.save(model.state_dict(), 'densenet_imagenet_scratch_best.pth')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 4225553,
     "sourceId": 6799,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
